{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119dfbb4",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/pandas-dev/pandas/raw/master/web/pandas/static/img/pandas.svg\" alt=\"pandas Logo\" style=\"width: 800px;\"/></center>\n",
    "\n",
    "# Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a033461",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Introduction to pandas data structures\n",
    "1. How to slice and dice pandas dataframes and dataseries\n",
    "1. How to use pandas for exploratory data analysis\n",
    "\n",
    "## Credits\n",
    "\n",
    "This notebook is part of the [Project Pythia foundations series](https://foundations.projectpythia.org/core/pandas/pandas.html) ([link to github repo](https://github.com/ProjectPythia/pythia-foundations)).  [LICENSE](https://github.com/ProjectPythia/pythia-foundations/blob/main/LICENSE)\n",
    "\n",
    "* **Time to learn**: 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dda6b4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5715a22",
   "metadata": {},
   "source": [
    "You will often see the nickname `pd` used as an abbreviation for pandas in the import statement, just like `numpy` is often imported as `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbfe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec773d2",
   "metadata": {},
   "source": [
    "## The pandas [`DataFrame`](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe)...\n",
    "... is a **labeled**, two dimensional columnal structure similar to a table, spreadsheet, or the R `data.frame`.\n",
    "\n",
    "![dataframe schematic](https://github.com/pandas-dev/pandas/raw/master/doc/source/_static/schemas/01_table_dataframe.svg \"Schematic of a pandas DataFrame\")\n",
    "\n",
    "The `columns` that make up our `DataFrame` can be lists, dictionaries, NumPy arrays, pandas `Series`, or more. Within these `columns` our data can be any texts, numbers, dates and times, or many other data types you may have encountered in Python and NumPy. Shown here on the left in dark gray, our very first `column`  is uniquely referrred to as an `Index`, and this contains information characterizing each row of our `DataFrame`. Similar to any other `column`, the `index` can label our rows by text, numbers, `datetime`s (a popular one!), or more.\n",
    "\n",
    "## Sea surface temperature measurements\n",
    "\n",
    "For this notebook we will be looking at temperature timeseries used to monitor the  El Ni√±o Southern Oscillation (ENSO). The data are provided by  the US National Climatic Data Center.  You can read about the regions \n",
    "corresponding to the various sea surface temperatures (Nino12, Nino3 and Nino4) [at the NCDC website](https://www.ncdc.noaa.gov/teleconnections/enso/indicators/sst/).\n",
    "\n",
    "[Here is an animation showing](https://drive.google.com/file/d/1Wf_FQglTU4fMZ5imAsHczAr0hcg4h1Ej/view?usp=sharing) the Southern Oscilation\n",
    "\n",
    "We start by reading in the data, formated as comma separated values.  You can download the enso_data.csv file [at this dropbox link](https://www.dropbox.com/s/afxfi6a0odoyx9y/enso_data.csv?dl=0).  If you are on our jupyterhub, it will\n",
    "already be in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea92812",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"enso_data.csv\"\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea110130",
   "metadata": {},
   "source": [
    "If we print out our dataframe, you will notice that is text based, which is okay, but not the \"best\" looking output.  All numbers are temperatures in deg Celsius.  \"anom\" is short for anomaly, which is defined as the\n",
    "fluctuation about the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755fd0d",
   "metadata": {},
   "source": [
    "If we just use the pandas dataframe itself (without wrapping it in `print`), we have a nicely rendered table which is native to pandas and Jupyter Notebooks. See how much nicer that looks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f7968",
   "metadata": {},
   "source": [
    "The `index` within pandas is essentially a list of the unique row IDs, which by default, is a list of sequential integers which start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ff349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2567a45",
   "metadata": {},
   "source": [
    "Our indexing column isn't particularly helpful currently. Pandas is clever! A few optional keyword arguments later, and..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath, index_col=0, parse_dates=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78a077",
   "metadata": {},
   "source": [
    "... now we have our data helpfully organized by a proper `datetime`-like object. Each of our multiple columns of data can now be referenced by their date! This sneak preview at the pandas `DatetimeIndex` also unlocks for us much of pandas most useful time series functionality. Don't worry, we'll get there. What are the actual columns of data we've read in here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae394c36",
   "metadata": {},
   "source": [
    "## The pandas [`Series`](https://pandas.pydata.org/docs/user_guide/dsintro.html#series)...\n",
    "\n",
    "... is essentially any one of the columns of our `DataFrame`, with its accompanying `Index` to provide a label for each value in our column.\n",
    "\n",
    "![pandas Series](https://github.com/pandas-dev/pandas/raw/master/doc/source/_static/schemas/01_table_series.svg \"Schematic of a pandas Series\")\n",
    "\n",
    "The pandas `Series` is a fast and capable 1-dimensional array of nearly any data type we could want, and it can behave very similarly to a NumPy `ndarray` or a Python `dict`. You can take a look at any of the `Series` that make up your `DataFrame` with its label and the Python `dict` notation, or with dot-shorthand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Nino34\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924aea16",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> You can also use the `.` (dot) notation, as seen below, but this is moreso a \"convenience feature\", which for the most part is interchangeable with the dictionary notation above, except when the column name is not a valid Python object (ex. column names beginning with a number or a space)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03898148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Nino34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717230fb",
   "metadata": {},
   "source": [
    "## Slicing and Dicing the `DataFrame` and `Series`\n",
    "\n",
    "We will expand on what you just saw, soon! Importantly,\n",
    "\n",
    "> **Everything in pandas can be accessed with its label**,\n",
    "\n",
    "no matter how your data is organized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fde7e",
   "metadata": {},
   "source": [
    "### Indexing a `Series`\n",
    "\n",
    "Let's back up a bit here. Once more, let's pull out one `Series` from our `DataFrame` using its column label, and we'll start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series = df[\"Nino34\"]\n",
    "\n",
    "nino34_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8d75c",
   "metadata": {},
   "source": [
    "`Series` can be indexed, selected, and subset as both `ndarray`-like,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b57d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d86b601",
   "metadata": {},
   "source": [
    "and `dict`-like, using labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7674a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series[\"1982-04-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed076e",
   "metadata": {},
   "source": [
    "These two can be extended in ways that you might expect,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ac036",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc96f03",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Info</p>\n",
    "    Index-based slices are <b>exclusive</b> of the final value, similar to Python's usual indexing rules.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a0f84",
   "metadata": {},
   "source": [
    "as well as potentially unexpected ways,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series[\"1982-01-01\":\"1982-12-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc269935",
   "metadata": {},
   "source": [
    "That's right, label-based slicing! Pandas will do the work under the hood for you to find this range of values according to your labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f39180",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Info</p>\n",
    "    label-based slices are <b>inclusive</b> of the final value, different from above!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb02320",
   "metadata": {},
   "source": [
    "If you are familiar with [xarray](../xarray), you might also already have a comfort with creating your own `slice` objects by hand, and that works here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a220a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series[slice(\"1982-01-01\", \"1982-12-01\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f7360",
   "metadata": {},
   "source": [
    "### Using `.iloc` and `.loc` to index\n",
    "\n",
    "Let's introduce pandas-preferred ways to access your data by label, `.loc`, or by index, `.iloc`. They behave similarly to the notation introduced above, but provide more speed, security, and rigor in your value selection, as well as help you avoid [chained assignment warnings](https://pandas.pydata.org/docs/user_guide/indexing.html#returning-a-view-versus-a-copy) within pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69149e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f083b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series.iloc[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c61c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series.loc[\"1982-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51edd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series.loc[\"1982-01-01\":\"1982-12-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e18385",
   "metadata": {},
   "source": [
    "### Extending to the `DataFrame`\n",
    "\n",
    "These capabilities extend back to our original `DataFrame`, as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cab7b0",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "df.loc[\"1982-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d70a1",
   "metadata": {},
   "source": [
    "They do! Importantly however, indexing a `DataFrame` can be more strict. A DataFrame has both rows and columns,\n",
    "and pandas needs to know that you are asking for a row, which is why you need to access the row label by\n",
    "using the `.loc` index.  If you give the DataFrame a single index, it will assume that you are asking\n",
    "for a column (the default) and not a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Nino34\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb588a64",
   "metadata": {},
   "source": [
    "You can also retrieve a row by its row number, but again, to remove the ambiguity between index labels (.loc)\n",
    "and row numbers, you need to use the `.iloc` locater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d7ad6",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0a43e",
   "metadata": {},
   "source": [
    "Knowing now that we can pull out one of our columns as a series with its label, plus our experience interacting with the `Series` `df[\"Nino34\"]` gives us, we can chain our brackets to pull out any value from any of our columns in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Nino34\"][\"1982-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Nino34\"][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84d0bc",
   "metadata": {},
   "source": [
    "However, this is not a pandas-preferred way to index and subset our data, and has limited capabilities for us. As we touched on before, `.loc` and `.iloc` give us more to work with, and their functionality grows further for `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"1982-04-01\", \"Nino34\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777963c",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Info</p>\n",
    "    Note the <code>[<i>row</i>, <i>column</i>]</code> ordering!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8839f",
   "metadata": {},
   "source": [
    "These allow us to pull out entire rows of `df`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"1982-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa136a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"1982-01-01\":\"1982-12-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c440076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d76a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d15c5",
   "metadata": {},
   "source": [
    "Even further,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74265858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    \"1982-01-01\":\"1982-12-01\",  # slice of rows\n",
    "    [\"Nino12\", \"Nino3\", \"Nino4\", \"Nino34\"],  # list of columns\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319ff30",
   "metadata": {},
   "source": [
    "### Indexing summary\n",
    "\n",
    "Here are some rules of thumb for all of these different ways of indexing into a pandas\n",
    "dataframe:\n",
    "\n",
    "\n",
    "1.  Use informative index labels for rows and columns if possible.  It's very\n",
    "    useful to be able to write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cded087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"1982-01-01\":\"1982-5-01\",\"Nino34\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d815b",
   "metadata": {},
   "source": [
    "This is self-documenting, does the datetime to row number conversion for you,\n",
    "and relieves you of worrying about what happens to the row and column\n",
    "numbers if you add more dates (say a year before 1982) or additional columns, removing\n",
    "a large number of potential bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f6201",
   "metadata": {},
   "source": [
    "2. Prefer `df.loc[\"1982-01-01\":\"1982-5-01\",\"Nino34\"]` to\n",
    "\n",
    "   `df[\"Nino34\"][\"1982-01-01\":\"1982-5-01\"]`\n",
    "   \n",
    "   Both statements return the same data frame, but the second version fetches the entire\n",
    "   column, then gets the rows from that column.  This results in a \n",
    "   column,row indexing order that is reversed from\n",
    "   the usual numpy row-major array indexing of row,column -- a potential source of confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa38c9",
   "metadata": {},
   "source": [
    "3. Use iloc only when you have to\n",
    "\n",
    "So given the two points above, why does pandas have iloc?  This is to cover a situation like\n",
    "this: suppose you need to return a new dataframe with the 10 warmest Nino34 temperatures.  To do that you need \n",
    "to be able to access the sorted rows by number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# sort in descending order\n",
    "#\n",
    "sorted_df = df.sort_values('Nino34',axis=0,ascending=False)\n",
    "#\n",
    "# get the top five temperatures, all columns\n",
    "#\n",
    "big_temps = sorted_df.iloc[:5,:]\n",
    "big_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe0e85",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Info</p>\n",
    "    For a more comprehensive explanation, which includes additional examples, limitations, and compares indexing methods between DataFrame and Series see <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html\">pandas' rules for indexing.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f98eb4",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "### Get a Quick Look at the Beginning/End of your `Dataframe`\n",
    "Pandas also gives you a few shortcuts to quickly investigate entire `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a60a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691504a",
   "metadata": {},
   "source": [
    "### Quick Plots of Your Data\n",
    "A good way to explore your data is by making a simple plot. Pandas allows you to plot without even calling `matplotlib`! Here, we are interested in the `Nino34` series. Check this out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = df.Nino34.plot(label='Nino34')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158678bf",
   "metadata": {},
   "source": [
    "Since we've kept the matplotlib axis handle returned by pandas, we can customize it and redraw\n",
    "the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887fdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0.set(ylabel='temperature (degC)')\n",
    "ax0.grid(True)\n",
    "ax0.legend(loc='lower right')\n",
    "display(ax0.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8867de",
   "metadata": {},
   "source": [
    "Before, we called `.plot()` which generated a single line plot. This is helpful, but there are other plots which can also help with understanding your data! Let's try using a histogram to understand distributions...\n",
    "\n",
    "The only part that changes here is we are subsetting for just two `Nino` indices, and after `.plot`, we include `.hist()` which stands for histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be331e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "axhist = df[['Nino12', 'Nino34']].plot.hist()\n",
    "axhist.set(xlabel='temperature (degC)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0218ff",
   "metadata": {},
   "source": [
    "We can see some clear differences in the distributions, which is helpful! Another plot one might like to use would be a `boxplot`. Here, we replace `hist` with `box`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2874123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Nino12', 'Nino34']].plot.box();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85903c47",
   "metadata": {},
   "source": [
    "Here, we again see a clear difference in the distributions. These are not the only plots you can use within pandas! For more examples of plotting choices, check out [the pandas plot documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bd264",
   "metadata": {},
   "source": [
    "#### More on customizing your plot -- use an existing figure with plt.subplots\n",
    "\n",
    "Pandas DataFrame `plot()` methods are just wrappers around matplotlib, so you always have the option to use matlplotlib directly\n",
    "instead of calling it through pandas.  Suppose you want the Nino34 graph to be one of four separate plots\n",
    "in a figure?  In that case, you can create a 2 x 2 set of axes with `plt.subplots`, \n",
    "and pass that axis to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "#\n",
    "# pass dataframe an existing matplotlib axis to draw on\n",
    "#\n",
    "df.Nino34.plot(ax=ax1,color='black',linewidth=2)\n",
    "ax1.set(xlabel='Year',\n",
    "       ylabel = 'ENSO34 Index (degC)',label='Nino34')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758f978",
   "metadata": {},
   "source": [
    "Alternatively, from matplotlib you can plot the dataframe in an axis using the matplotlib `data` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(1,1, figsize=(8,6))\n",
    "#\n",
    "# any dictionary-like object with keys and data will\n",
    "# work here, if it's passed using the data keyword and\n",
    "# the key is in the dicitonary\n",
    "#\n",
    "ax2.plot('Nino34',data = df);\n",
    "ax2.set(xlabel='Year',\n",
    "       ylabel = 'ENSO34 Index (degC)',label='Nino34')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f20545",
   "metadata": {},
   "source": [
    "**Bottom line**:  Do you want pandas or matplotlib to be in control of your plotting?  We've shown you multiple\n",
    "ways to plot a figure.\n",
    "\n",
    "1. Simplest -- pandas.DataFrame.plot(), put pandas in control of your figure and axis.\n",
    "\n",
    "2. More flexible -- have matplotlib control the figure and axis, and pass that axis to pandas for plotting using the `ax` keyword in pandas.DataFrame.plot()\n",
    "\n",
    "3. Matplotlib in control -- pass the DataFrame to the ax.plot function directly using the `data` keyword in matlotlib.axis.plot()\n",
    "\n",
    "Which to choose depends on how much customization you need -- using pandas plot functions\n",
    "may be easier, but they also add an extra layer on top of matplotlib that could potentially make your\n",
    "code more opaque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d36e3",
   "metadata": {},
   "source": [
    "Next: graphs are a great way to get a feel for your data, but what if you wanted a more ***quantitative*** perspective? We can use the `describe` method on our `DataFrame`; this returns a table of summary statistics for all columns in the `DataFrame`\n",
    "\n",
    "### Basic Statistics\n",
    "\n",
    "By using the `describe` method, we see some general statistics! Notice how calling this on the dataframe returns a table with all the `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df5f77",
   "metadata": {},
   "source": [
    "You can look at specific statistics too, such as mean! Notice how the output is a `Series` (column) now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c818930a",
   "metadata": {},
   "source": [
    "If you are interested in a single column mean, subset for that and use `.mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Nino34.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff7c71",
   "metadata": {},
   "source": [
    "### Subsetting Using the Datetime Column\n",
    "\n",
    "You can use techniques besides slicing to subset a `DataFrame`. Here, we provide examples of using a couple other options.\n",
    "\n",
    "Say you only want the month of January - you can use `df.index.month` to query for which month you are interested in (in this case, 1 for the month of January)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the datetime column\n",
    "df[df.index.month == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82cc31",
   "metadata": {},
   "source": [
    "You could even assign this month to a new column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde7417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789598c",
   "metadata": {},
   "source": [
    "Now that it is its own column (`Series`), we can use `groupby` to group by the month, then taking the average, to determine average monthly values over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('month').mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8b200",
   "metadata": {},
   "source": [
    "#### Pandas style hint:  method chaining\n",
    "\n",
    "The cell above \"chains\" two methods (mean and plot) together, without creating an intermediate result.  It's equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66650fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_groups = df.groupby('month')\n",
    "month_mean = month_groups.mean()\n",
    "the_axis = month_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c69bc3",
   "metadata": {},
   "source": [
    "It's very common in pandas to see chained methods written  one methoc per line-- can you explain why this works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_ax = (df.groupby('month')\n",
    "          .mean()\n",
    "          .plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e260f",
   "metadata": {},
   "source": [
    "#### Your turn\n",
    "\n",
    "Add a grid, title and a yaxis label to this plot using the `the_ax` axis.  See the [matplotlib gallery](https://matplotlib.org/stable/gallery/index.html) for some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05e211",
   "metadata": {},
   "source": [
    "### Turning a groupby result into a dictionary\n",
    "\n",
    "\n",
    "\n",
    "Here is an incantation that turns a groupby object into a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9baab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_groups = df.groupby('month')\n",
    "month_groups = dict(tuple(month_groups))\n",
    "month_groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdb9d4",
   "metadata": {},
   "source": [
    "#### Your turn\n",
    "\n",
    "What steps would you take to figure out why `dict(tuple(month_groups))` works the way it does?  Here's a good\n",
    "[overview of dicitionaries](https://realpython.com/iterate-through-dictionary-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57194ea2",
   "metadata": {},
   "source": [
    "### Investigating Extreme Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e8eb5",
   "metadata": {},
   "source": [
    "You can also use ***conditional indexing***, such that you can search where rows meet a certain criteria. In this case, we are interested in where the Nino34 anomaly is greater than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Nino34anom > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2da03",
   "metadata": {},
   "source": [
    "You can also sort columns based on the values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de577b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Nino34anom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99674b77",
   "metadata": {},
   "source": [
    "Let's change the way that is ordered..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Nino34anom', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f97e5a2",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "Here, we are trying to resample the timeseries such that the signal does not appear as noisy. This can helpfule when working with timeseries data! In this case, we resample to a yearly average (`1Y`) instead of monthly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f560c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Nino34.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9dcc95",
   "metadata": {},
   "source": [
    "#### Your turn\n",
    "\n",
    "How would you plot the original timeseries on top of the one year resample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed08576",
   "metadata": {},
   "source": [
    "### Applying operations to a dataframe\n",
    "\n",
    "Often times, people are interested in applying calculations to data within pandas `DataFrame`s. Here, we setup a function to convert from degrees Celsius to Kelvin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_degc_to_kelvin(temperature_degc):\n",
    "    \"\"\"\n",
    "    Converts from degrees celsius to Kelvin\n",
    "    \"\"\"\n",
    "\n",
    "    return temperature_degc + 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212ab12",
   "metadata": {},
   "source": [
    "Now, this function accepts and returns a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a single value\n",
    "convert_degc_to_kelvin(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d146439",
   "metadata": {},
   "source": [
    "But what if we want to apply this to our dataframe? We can subset for Nino34, which is in degrees Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81348288",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino34_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e44535",
   "metadata": {},
   "source": [
    "Notice how the object type is a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.Nino12[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80a96b",
   "metadata": {},
   "source": [
    "If you call `.values`, the object type is now a numpy array. Pandas `Series` values include numpy arrays, and calling `.values` returns the series as a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.Nino12.values[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04795987",
   "metadata": {},
   "source": [
    "Let's apply this calculation to this `Series`; this returns another `Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01088854",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_degc_to_kelvin(nino34_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66d668",
   "metadata": {},
   "source": [
    "If we include `.values`, it returns a `numpy array`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ff36d",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Warning</p>\n",
    "    We don't usually recommend converting to NumPy arrays unless you need to - once you convert to NumPy arrays, the helpful label information is lost... so beware! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95892aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_degc_to_kelvin(nino34_series.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d97a82",
   "metadata": {},
   "source": [
    "We can now assign our pandas `Series` with the converted temperatures to a new column in our dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80311ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Nino34_degK'] = convert_degc_to_kelvin(nino34_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1384219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Nino34_degK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0fe0b8",
   "metadata": {},
   "source": [
    "Now that our analysis is done, we can save our data to a `csv` for later - or share with others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c056db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nino_analyzed_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('nino_analyzed_output.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85024e60",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* Pandas is a very powerful tool for working with tabular (i.e. spreadsheet-style) data\n",
    "* There are multiple ways of subsetting your pandas dataframe or series\n",
    "* Pandas allows you to refer to subsets of data by label, which generally makes code more readable and more robust\n",
    "* Pandas can be helpful for exploratory data analysis, including plotting and basic statistics\n",
    "* One can apply calculations to pandas dataframes and save the output via `csv` files\n",
    "\n",
    "\n",
    "## Resources and References\n",
    "1. [NOAA NCDC ENSO Dataset Used in this Example](https://www.ncdc.noaa.gov/teleconnections/enso/indicators/sst/)\n",
    "1. [Getting Started with Pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started)\n",
    "1. [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)\n",
    "1. [Modern Pandas](https://tomaugspurger.github.io/modern-1-intro)\n",
    "1. [Python dictionaries](https://realpython.com/iterate-through-dictionary-python/)\n",
    "1. [Matplotlib gallery](https://matplotlib.org/stable/gallery/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

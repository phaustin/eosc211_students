{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab60b794",
   "metadata": {},
   "source": [
    "# File IO\n",
    "\n",
    "## EOSC 211\n",
    "\n",
    "**Week 12 Day 2**\n",
    "\n",
    "**Learning Objectives:** \n",
    "\n",
    "1. Convert python datatypes (arrays, datetime slices) into basic\n",
    "   strings, lists, tuples, dicts that can be saved to a text file in json format\n",
    "2. Write a function to open a json file and convert the file contents back\n",
    "   into python objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8d579",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this course we've usually started a worksheet or lab by reading a data file into python.  For example,\n",
    "in [wk05_indexing](https://phaustin.github.io/eosc211_students/wk05/wk05_indexing.html) we used\n",
    "`np.load` to read in a dictionary containing two numpy binary files containing the arrays `flux` and `temp`.\n",
    "As I mentioned in that notebook, these files were written by  [np.savez](https://numpy.org/doc/stable/reference/generated/numpy.savez.html).  In [week 11](https://phaustin.github.io/eosc211_students/wk11/pythia_pandas.html) you used `pd.read_csv` to read in\n",
    "a text file written in spreadsheet `comma separated value` format.  This [enso_data.csv](https://github.com/phaustin/eosc211_students/blob/e211_live_main/wk11/enso_data.csv) file was written\n",
    "from a dataframe using [pandas.DataFrame.to_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html).  \n",
    "\n",
    "Writing binary numpy files and csv files from dataframes works: but there is a significant drawback,\n",
    "you need numpy and some kind of spreadsheet to read the data.  How would you write a file\n",
    "that any text editor or programming language could work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9c00c",
   "metadata": {},
   "source": [
    "## Background -- text vs. binary\n",
    "\n",
    "What is the difference between a text file like `enso_data.csv` and a binary file like `temp_flux.npz`?  At the\n",
    "machine level, there is no difference, like everything else on your computer, they consist only of a\n",
    "long string of 1's and 0's.  The difference is in how a computer program interprets those 1's and 0's. \n",
    "\n",
    "In a text file, the 8 bit bytes are mapped to characters in a human language using a lookup table.\n",
    "Python (and all modern programming languages) uses the [unicode character table](https://unicode-table.com/en/blocks/), which includes not only languages, but [math](https://unicode-table.com/en/blocks/mathematical-operators/), [emojis, musical notes and chess pieces](https://unicode-table.com/en/blocks/miscellaneous-symbols/) \n",
    "\n",
    "In a binary file, the bits are read into memory with no assumption about a mapping. You need to know\n",
    "whether the bits were written as 64 bit floats, 32 bit ints, or 1 bit logical values.  This quickly gets\n",
    "complicated -- there is a brief note about packages that write common binary data formats at the \n",
    "end of the worksheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c99d5",
   "metadata": {},
   "source": [
    "## A basic text file example\n",
    "\n",
    "Here's basic  write of a numpy array to a text file using the folders we created in the week 11 lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8259afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "myhome = Path.home()\n",
    "\n",
    "# create the folder\n",
    "text_dir = myhome / 'eosc211/week12'\n",
    "text_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# make some data and write it out\n",
    "simple_vec = np.arange(3,40,2)\n",
    "filename = text_dir / 'simplefile.txt'\n",
    "with open(filename,'w') as outfile:\n",
    "    for the_num in simple_vec:\n",
    "        outfile.write(f\"{the_num}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c3dcf",
   "metadata": {},
   "source": [
    "The last block of code above uses `open` to open a file for writing (which will\n",
    "overwrite anything that was already there) and then converts each floating point number into\n",
    "a string and writes that to the file, including a newline `\\n`.  The `with` statement\n",
    "handles closing the file safely once you've left the `with context block`\n",
    "\n",
    "Check that this works by launching a text editor to look at the file:\n",
    "\n",
    "```\n",
    "cd ~/eosc211/week12\n",
    "start simplefile.txt  (for windows)\n",
    "open simplefile.txt  (for macs)\n",
    "```\n",
    "\n",
    "or using the text file editor on our jupyterhub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82da096",
   "metadata": {},
   "source": [
    "## An easier way\n",
    "\n",
    "\n",
    "That's quite a bit of work to write out a couple of numbers.  Python provides a variety of modules\n",
    "that allow you to skip all this bookkeeping, as long as your data consists of basic python types:\n",
    "`strings, lists, tuples, or dictionaries` and you want to save using a common format (like csv).\n",
    "One very common general text file format is `json` (javascript object notation).  Here is the same\n",
    "file written in json.  We'll try a 3-d array this time.  We need to first turn the array into\n",
    "a list, then dump the list to the file using [json.dump](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79e14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#\n",
    "# make a 3-d array\n",
    "#\n",
    "simple_vec = np.arange(0,100)\n",
    "simple_vec = simple_vec.reshape(5,5,4)\n",
    "#\n",
    "# write out as a json list\n",
    "#\n",
    "json_file = text_dir / 'simplefile.json'\n",
    "with open(json_file, 'w') as json_out:\n",
    "    my_list = simple_vec.tolist()\n",
    "    json.dump(my_list, json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2927c",
   "metadata": {},
   "source": [
    "Take a look at that file, and double check that you can read it back in. Note that the\n",
    "numpy `tolist` method correctly handles the nested rows, and the numpy `array` construct\n",
    "correctly `round-trips` the list back to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4160d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[20 21]\n",
      "  [24 25]]\n",
      "\n",
      " [[40 41]\n",
      "  [44 45]]\n",
      "\n",
      " [[60 61]\n",
      "  [64 65]]\n",
      "\n",
      " [[80 81]\n",
      "  [84 85]]]\n"
     ]
    }
   ],
   "source": [
    "with open(json_file) as json_in:\n",
    "    new_vec = json.load(json_in)\n",
    "new_vec = np.array(new_vec)\n",
    "print(new_vec[:,:2,:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e5cac",
   "metadata": {},
   "source": [
    "## Including metadata\n",
    "\n",
    "You want to avoid writing out naked lists of raw numbers without extra information (called metadata) like\n",
    "physical units, uncertainty estimates, etc.  You can do this with json using a dictionary that contains\n",
    "your list along with other strings, lists and dictionaries if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfb9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {}\n",
    "my_data['units'] = 'deg C'\n",
    "my_data['plot_title'] = \"incubator temperature\"\n",
    "my_data['valid range'] = (-10,100)\n",
    "my_data['missing_values'] = -999\n",
    "my_data['comment']='first run incubator temperature test'\n",
    "my_data['first_run'] = simple_vec.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336de18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = text_dir / 'metadata.json'\n",
    "#\n",
    "# indent 4 spaces\n",
    "#\n",
    "with open(meta_file,'w') as meta_out:\n",
    "    json.dump(my_data, meta_out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142bc3d5",
   "metadata": {},
   "source": [
    "Take a look at this file, and notice that the `indent=4` added nested spaces to make the various\n",
    "levels more readable.  Since whitespace isn't significant in json files, those space will be ignored\n",
    "when your read it back in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec6cb9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['units', 'plot_title', 'valid range', 'missing_values', 'comment', 'first_run'])\n"
     ]
    }
   ],
   "source": [
    "with open(meta_file) as meta_in:\n",
    "    new_dict = json.load(meta_in)\n",
    "print(new_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4cd804",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To write general data out to a text file you need to choose a text file format (we've seen csv and json, but\n",
    "there are hundreds of different special formats) and then convert your data into datatypes that\n",
    "the output file format can understand.  Since this is such a common task, almost all python objects have\n",
    "some way to represent themselves as lists, dicts, or strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcff3d",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Put the following items in a dictionary, and write that dictionary to a json file called\n",
    "`parameters.json` in your week12 folder:\n",
    "\n",
    "1) A list of 3 datetime objects -- with the key `the_dates`  \n",
    "2) the start and stop values for a slice, with keys `start` and `stop`\n",
    "\n",
    "One way to convert a datetime object into a string is to use the\n",
    "[isoformat](https://docs.python.org/3/library/datetime.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bdab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd991416",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Write a function called `process_params` that takes the filename (as a Path object) and returns a dictionary,\n",
    "holding a list of datetime objects (dictionary key: `the_dates`) converted form their isoformat strings, and the\n",
    "start and stop values converted to a slice object stored in dictionary key `the_slice`.  \n",
    "The datetime module provides the function `datetime.datetime.fromisoformat`\n",
    "to go from iso strings back to datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b4f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2e762",
   "metadata": {},
   "source": [
    "## Postscript: writing binary files\n",
    "\n",
    "This is all fine for text files, but what if you need to write out 3 Mbytes of binary arrays?  Converting\n",
    "all of that to and from text is a major waste of cpu time and disk space.   For this course, the choice would\n",
    "be to write out an npz file, and accompanying that npz file with a json file holding whatever metadata\n",
    "you want to include (especially the file name of the npz file, so you don't lose track).  Once you\n",
    "get beyond this course however, it's good to know that there is common workflow. Specifically: \n",
    "we recommend the following steps:\n",
    "\n",
    "1) Convert your numpy array to an [xarray Dataset](https://foundations.projectpythia.org/core/xarray/xarray.html)  \n",
    "2) Use xarray to write out the data in a common binary format. The two most common binary data formats\n",
    "   in the earth sciences are [netcdf](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_netcdf.html)\n",
    "   and [zarr](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_zarr.html)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "source_map": [
   13,
   28,
   43,
   59,
   65,
   80,
   97,
   109,
   123,
   129,
   134,
   142,
   152,
   159,
   165,
   169,
   178,
   191,
   193,
   203,
   205
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}